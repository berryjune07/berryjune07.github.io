<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2025-12-15T11:06:52+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Jiho’s Blog</title><subtitle>noting down my thoughts and experiences
</subtitle><author><name>Jiho Jun</name><email>pianoforte0203@gmail.com</email></author><entry><title type="html">Antiderivatives</title><link href="http://localhost:4000/mathematics/antiderivatives.html" rel="alternate" type="text/html" title="Antiderivatives" /><published>2025-11-30T00:00:00+09:00</published><updated>2025-11-30T00:00:00+09:00</updated><id>http://localhost:4000/mathematics/antiderivatives</id><content type="html" xml:base="http://localhost:4000/mathematics/antiderivatives.html">&lt;!--more--&gt;
* this unordered seed list will be replaced by the toc
{:toc}</content><author><name>Jiho Jun</name><email>pianoforte0203@gmail.com</email></author><category term="mathematics" /><category term="calculus" /><summary type="html"></summary></entry><entry><title type="html">Convexity of a Function and the Second Derivative Test</title><link href="http://localhost:4000/mathematics/convexity-of-a-function-and-the-second-derivative-test.html" rel="alternate" type="text/html" title="Convexity of a Function and the Second Derivative Test" /><published>2025-11-29T00:00:00+09:00</published><updated>2025-11-29T00:00:00+09:00</updated><id>http://localhost:4000/mathematics/convexity-of-a-function-and-the-second-derivative-test</id><content type="html" xml:base="http://localhost:4000/mathematics/convexity-of-a-function-and-the-second-derivative-test.html">&lt;!--more--&gt;
* this unordered seed list will be replaced by the toc
{:toc}</content><author><name>Jiho Jun</name><email>pianoforte0203@gmail.com</email></author><category term="mathematics" /><category term="calculus" /><summary type="html"></summary></entry><entry><title type="html">Strongly Connected Components</title><link href="http://localhost:4000/computer-science/strongly-connected-components.html" rel="alternate" type="text/html" title="Strongly Connected Components" /><published>2025-11-28T00:00:00+09:00</published><updated>2025-11-28T00:00:00+09:00</updated><id>http://localhost:4000/computer-science/strongly-connected-components</id><content type="html" xml:base="http://localhost:4000/computer-science/strongly-connected-components.html">&lt;!--more--&gt;
* this unordered seed list will be replaced by the toc
{:toc}</content><author><name>Jiho Jun</name><email>pianoforte0203@gmail.com</email></author><category term="computer-science" /><category term="algorithms" /><summary type="html"></summary></entry><entry><title type="html">Monotonic Functions and the First Derivative Test</title><link href="http://localhost:4000/mathematics/monotonic-functions-and-the-first-derivative-test.html" rel="alternate" type="text/html" title="Monotonic Functions and the First Derivative Test" /><published>2025-11-28T00:00:00+09:00</published><updated>2025-11-28T00:00:00+09:00</updated><id>http://localhost:4000/mathematics/monotonic-functions-and-the-first-derivative-test</id><content type="html" xml:base="http://localhost:4000/mathematics/monotonic-functions-and-the-first-derivative-test.html">&lt;!--more--&gt;
* this unordered seed list will be replaced by the toc
{:toc}</content><author><name>Jiho Jun</name><email>pianoforte0203@gmail.com</email></author><category term="mathematics" /><category term="calculus" /><summary type="html"></summary></entry><entry><title type="html">Topological Sorting</title><link href="http://localhost:4000/computer-science/topological-sorting.html" rel="alternate" type="text/html" title="Topological Sorting" /><published>2025-11-27T00:00:00+09:00</published><updated>2025-11-27T00:00:00+09:00</updated><id>http://localhost:4000/computer-science/topological-sorting</id><content type="html" xml:base="http://localhost:4000/computer-science/topological-sorting.html">&lt;!--more--&gt;
* this unordered seed list will be replaced by the toc
{:toc}</content><author><name>Jiho Jun</name><email>pianoforte0203@gmail.com</email></author><category term="computer-science" /><category term="algorithms" /><summary type="html"></summary></entry><entry><title type="html">The Mean Value Theorem</title><link href="http://localhost:4000/mathematics/the-mean-value-theorem.html" rel="alternate" type="text/html" title="The Mean Value Theorem" /><published>2025-11-27T00:00:00+09:00</published><updated>2025-11-27T00:00:00+09:00</updated><id>http://localhost:4000/mathematics/the-mean-value-theorem</id><content type="html" xml:base="http://localhost:4000/mathematics/the-mean-value-theorem.html">&lt;!--more--&gt;
* this unordered seed list will be replaced by the toc
{:toc}

## Rolle&apos;s Theorem

**Rolle&apos;s Theorem** is a Lemma that serves as a foundation for the Mean Value Theorem.
&gt; Let $f$ be a continuous function on the closed interval $[a, b]$ and differentiable on the open interval $(a, b)$.
If $f(a) = f(b)$, then there exists at least one point $c \in (a, b)$ such that $f^\prime(c) = 0$.</content><author><name>Jiho Jun</name><email>pianoforte0203@gmail.com</email></author><category term="mathematics" /><category term="calculus" /><summary type="html"></summary></entry><entry><title type="html">Euler Tour Technique</title><link href="http://localhost:4000/computer-science/euler-tour-technique.html" rel="alternate" type="text/html" title="Euler Tour Technique" /><published>2025-11-26T00:00:00+09:00</published><updated>2025-11-26T00:00:00+09:00</updated><id>http://localhost:4000/computer-science/euler-tour-technique</id><content type="html" xml:base="http://localhost:4000/computer-science/euler-tour-technique.html">&lt;!--more--&gt;
* this unordered seed list will be replaced by the toc
{:toc}</content><author><name>Jiho Jun</name><email>pianoforte0203@gmail.com</email></author><category term="computer-science" /><category term="algorithms" /><summary type="html"></summary></entry><entry><title type="html">Merge Sort Tree</title><link href="http://localhost:4000/computer-science/merge-sort-tree.html" rel="alternate" type="text/html" title="Merge Sort Tree" /><published>2025-11-12T00:00:00+09:00</published><updated>2025-11-12T00:00:00+09:00</updated><id>http://localhost:4000/computer-science/merge-sort-tree</id><content type="html" xml:base="http://localhost:4000/computer-science/merge-sort-tree.html">&lt;!--more--&gt;
* this unordered seed list will be replaced by the toc
{:toc}

## Introduction

A **merge sort tree** is a specialized data structure that combines the properties of a segment tree with the ability to efficiently perform range queries on sorted data.
It usually does not support updates efficiently.

## Merge Sort Tree

### Explanation

A merge sort tree is built on top of a segment tree, where each node contains a sorted list of elements corresponding to the segment it represents.
The tree is constructed by recursively dividing the array into segments and merging the sorted lists of child nodes.
Each node in the merge sort tree is a _multiset_ (or sorted array), and the merge sort tree can only efficiently answer range queries that satisfy the following condition:

- For the query function $F$, multisets $S_1,S_2$, and a query result combiner function $G(\cdot,\cdot)$,

\\[
F(S_1 \cup S_2) = G(F(S_1), F(S_2))
\\]

This means that the result of the query on the union of two multisets can be computed by combining the results of the queries on each individual multiset,
and $F$ only depends on the order statistics of the array.

For example, for an array $[4,3,7,1,2,1,2,5]$, the merge sort tree would be built as follows:

```mermaid
graph TD;
    A1[1,1,2,2,3,4,5,7];
    B1[1,3,4,7]; B2[1,2,2,5];
    C1[3,4]; C2[1,7]; C3[1,2]; C4[2,5];
    D1[4]; D2[3]; D3[7]; D4[1]; D5[2]; D6[1]; D7[2]; D8[5];
    
    A1 --&gt; B1; A1 --&gt; B2;
    B1 --&gt; C1; B1 --&gt; C2;
    B2 --&gt; C3; B2 --&gt; C4;
    C1 --&gt; D1; C1 --&gt; D2;
    C2 --&gt; D3; C2 --&gt; D4;
    C3 --&gt; D5; C3 --&gt; D6;
    C4 --&gt; D7; C4 --&gt; D8;
```

### Complexity

Suppose the size of the input array is $N$, it takes $O(T(N))$ time to compute the query for a segment.

\1. **Build**: $O(N \log N)$

It takes $O(A+B)$ time to merge two sorted lists of sizes $A$ and $B$.
Since the size of array is $N$ and at each level of the segment tree we merge $N$ elements,
it takes $O(N)$ time per level.
The height of the segment tree is $O(\log N)$, so the total time complexity for building the merge sort tree is $O(N \log N)$.

\2. **Query**: $O(T(N) \log N)$

From [here](/computer-science/segment-tree.html), we know that for each range query, we visit $O(\log N)$ nodes in the segment tree.
At each visited node, we perform a query on the sorted list stored in that node, which takes $O(T(N))$ time.
Therefore, the total time complexity for a range query is $O(T(N) \log N)$.

\3. **Space Complexity**: $O(N \log N)$

The space complexity of a merge sort tree is $O(N \log N)$ because each level of the segment tree stores $N$ elements in sorted lists, and there are $O(\log N)$ levels in the tree.

## Code

Let’s see the sample code.
```cpp
#define all(v) v.begin(),v.end()

const int N;
const int TREE_SIZE = 1 &lt;&lt; ((int)ceil(log2(N)) + 1);
using vec = vector&lt;data&gt;; // orderable data type

data A[N];
struct Node{
    vec v; // sorted array
    // other members if needed
} tree[TREE_SIZE];

Node merge_Node(Node a,Node b){
    Node res;
    res.v.resize(a.v.size()+b.v.size());
    merge(all(a.v), all(b.v), res.v.begin());
    // other member merges if needed
    return res;
}

Node conv(data a){
    Node res;
    res.v = {a};
    // other member initializations if needed
    return res;
}

q F(Node nd); // query function on a node
q G(q a,q b); // query result combiner function
q identity(); // return identity query result

Node init(int l,int r,int nd){
    if(l==r) return tree[nd] = conv(A[l]);
    int m = (l+r)/2;
    return tree[nd] = merge_Node(init(l,m,nd*2),init(m+1,r,nd*2+1));
}

q Query(int l,int r,int nd,int s,int e){
    if(e&lt;l or r&lt;s) return identity();
    if(s&lt;=l and r&lt;=e) return F(tree[nd]);
    int m = (l+r)/2;
    return G(Query(l,m,nd*2,s,e),Query(m+1,r,nd*2+1,s,e));
}
```

### Example

Suppose we want to count the number of elements less than or equal to a given value $K$ in a range $[L, R]$ of the array.

```cpp
int A[N];
struct Node{
    vec v;
} tree[TREE_SIZE];

int F(Node nd, int K){
    return upper_bound(all(nd.v), K)-nd.v.begin();
}
int G(int a,int b){
    return a + b;
}
int identity(){
    return 0;
}
```

In this example, time complexity of the query function $F$ is $T(N) = O(\log N)$ due to the binary search performed by `upper_bound`.
Thus, the overall time complexity for a range query becomes $O(\log^2 N)$.</content><author><name>Jiho Jun</name><email>pianoforte0203@gmail.com</email></author><category term="computer-science" /><category term="algorithms" /><summary type="html"></summary></entry><entry><title type="html">Mo’s Algorithm</title><link href="http://localhost:4000/computer-science/mos-algorithm.html" rel="alternate" type="text/html" title="Mo’s Algorithm" /><published>2025-11-12T00:00:00+09:00</published><updated>2025-11-12T00:00:00+09:00</updated><id>http://localhost:4000/computer-science/mos-algorithm</id><content type="html" xml:base="http://localhost:4000/computer-science/mos-algorithm.html">&lt;!--more--&gt;
* this unordered seed list will be replaced by the toc
{:toc}

## Introduction

**Mo&apos;s Algorithm** is an offline algorithm optimization technique to answer multiple range queries on a static array.
It employs an idea from the **[sqrt-decomposition](/computer-science/sqrt-decomposition.html)** technique, 
enabling us to answer each query averagely in $O\left( \sqrt{N} \right)$ time.

## Explanation

Mo&apos;s Algorithm can handle multiple range queries on a static array sorting the queries.
The queries should be able to be computed by adding or removing elements from the current range so that 
we can move the start and end pointers of the range to answer each query. We here use an idea from
the sqrt-decomposition technique; dividing the array into blocks of size approximately $\sqrt{N}$, and sorting the queries
first by the block of their start position, and then by their end position.

Mathematically speaking, we can answer a query $F([l,r])=F_s(f([l,r]))$ for an array $A=[a_1,\cdots,a_N]$ of size $N$ if $f$ satisfies the following properties:
 - $f([l,r+1]) = U_{\rm r}(f([l,r]), a_{r+1})$
 - $f([l,r-1]) = D_{\rm r}(f([l,r]), a_r)$
 - $f([l-1,r]) = U_{\rm l}(f([l,r]), a_{l-1})$
 - $f([l+1,r]) = D_{\rm l}(f([l,r]), a_l)$

where $U_{\rm r}$ and $D_{\rm r}$ are right adding and removing functions, $U_{\rm l}$ and $D_{\rm l}$ are left adding and removing functions respectively.
$f$ is a function that maps an range $[l,r]$ to a latent result, and $F_s$ is a function that maps the latent result to the final answer.
The functions should satisfy the following properties:
- $D_{\rm r}(U_{\rm r}(f([l,r]), a_{r+1}), a_{r+1}) = U_{\rm r}(D_{\rm r}(f([l,r]), a_r), a_r) = f([l,r])$
- $D_{\rm l}(U_{\rm l}(f([l,r]), a_{l-1}), a_{l-1}) = U_{\rm l}(D_{\rm l}(f([l,r]), a_l), a_l) = f([l,r])$

In other words, for all $x$,
- $U_{\rm r}(\cdot,x) = (D_{\rm r}(\cdot,x))^{-1}$
- $U_{\rm l}(\cdot,x) = (D_{\rm l}(\cdot,x))^{-1}$

This means, after computing $f([l_1,r_1])$, we can compute $f([l_2,r_2])$ by applying
$U_{\rm l}$ or $D_{\rm l}$ $\abs{l_2-l_1}$ times and $U_{\rm r}$ or $D_{\rm r}$ $\abs{r_2-r_1}$ times.
For the whole set of $Q$ queries, we should minimize the sum of the shifts:

\\[
\sum_{q=1}^{Q-1} \abs{l_q-l_{q+1}} + \abs{r_q-r_{q+1}}
\\]

and this can be done by a &quot;proper&quot; sorting of the queries explained above.

\\[
(l_1,r_1) &lt; (l_2,r_2) \;\Leftrightarrow\; \begin{cases}
\dps \left\lfloor \frac{l_1}{B} \right\rfloor &lt; \left\lfloor \frac{l_2}{B} \right\rfloor &amp;\nl
r_1 &lt; r_2 &amp; \text{if } \dps \left\lfloor \frac{l_1}{B} \right\rfloor = \left\lfloor \frac{l_2}{B} \right\rfloor
\end{cases}
\\]

where $B = \left\lceil \sqrt{N} \right\rceil$ is the block size.
Let&apos;s look at an example. For the following range queries,

\\[
\Set{(4,6),(5,9),(2,7),(3,4)}
\\]

we process them in the following order:

```mermaid
graph LR
    subgraph A[&quot;Block 1&quot;]
        direction LR;
        A1((1)); A2((2)); A3((3));
    end
    subgraph B[&quot;Block 2&quot;]
        direction LR;
        B1((4)); B2((5)); B3((6));
    end
    subgraph C[&quot;Block 3&quot;]
        direction LR;
        C1((7)); C2((8)); C3((9));
    end
    A1 --- A2 --- A3 --- B1 --- B2 --- B3 --- C1 --- C2 --- C3;
    A3 --&gt; A2 --&gt; B1 --&gt; B2;
    B1 -.-&gt; C1 -.-&gt; B3 -.-&gt; C3;
    linkStyle 0,1,2,3,4,5,6,7 stroke:transparent;
    A2:::q1; C1:::q1;
    A3:::q2; B1:::q2;
    B3:::q3;
    B2:::q4; C3:::q4;
    classDef q1 fill:#bbf,stroke:#333,stroke-width:2px;
    classDef q2 fill:#9bf,stroke:#333,stroke-width:2px;
    classDef q3 fill:#fdb,stroke:#333,stroke-width:2px;
    classDef q4 fill:#faa,stroke:#333,stroke-width:2px;
```

The solid lines are the shift of left pointers, and the dotted lines are the shift of right pointers.
Though it is not the global optimal minimum of the shifts, this method gives enough time complexity to handle lots of queries.

## Complexity

Denote $S(N)$ as the time complexity to shift the pointers by one position ($U_{\rm l}$, $D_{\rm l}$, $U_{\rm r}$, $D_{\rm r}$),
$T(N)$ as the time complexity to compute $F_s$ from the latent result.

\1. Sorting the queries: $O(Q \log Q)$

\2. Shifting the pointers: $O\left((N + Q) \sqrt{N} S(N)\right)$

Let&apos;s think of two cases: when successive queries have their start positions in the same block, and when they are in different blocks.
When they are in the same block, the left pointer shifts at most $B$ times, and the right pointer shifts at most $N$ times in total for all such queries since they are monotonically increasing.
Thus, the total shift number is $O\left( BQ + N \cdot \frac{N}{B} \right) = O\left( (N+Q) \sqrt{N} \right)$.
When they are in different blocks, the left and right pointers shift at most $N$ times each.
This case only occurs $O\left( \frac{N}{B} \right)$ times, so the total shift number is $O\left( N \cdot \frac{N}{B} \right) = O\left( N \sqrt{N} \right)$.
Therefore, the overall time complexity is $O\left( (N+Q) \sqrt{N} S(N) \right)$.

\3. Computing answers: $O(Q T(N))$

Thus, the overall time complexity is:

\\[
O\left( Q\log Q + (N+Q) \sqrt{N} S(N) + Q T(N) \right)
\\]

We usually use Mo&apos;s Algorithm for problems with $S(N) \approx O(1), T(N) \le O\left( \sqrt{N} \right)$
so that the overall time complexity becomes:

\\[
O\left( (N+Q) \sqrt{N} \right)
\\]

## Code

Let&apos;s see the sample code.

```cpp
const int N,Q;
const int B = ceil(sqrt(N)); // block size

struct Query {
    int l,r,idx;
    bool operator&lt;(const Query&amp; q) const {
        if(l/B != q.l/B) return l/B &lt; q.l/B;
        return r &lt; q.r;
    }
} query[Q];
q ans[Q];
data A[N];
latent f;

void Add(int x,bool dir); // add A[x] to the current range if(dir) right, else left, and update f
void Remove(int x,bool dir); // remove A[x] from the current range if(dir) right, else left, and update f
q GetAnswer(); // compute the final answer from f

void Mo(){
    sort(query,query+Q);
    int l=query[0].l, r=query[0].r, idx=query[0].idx;
    for(int i=l; i&lt;=r; i++) Addr(i);
    ans[idx] = GetAnswer();
    for(int i=1; i&lt;Q; i++){
        int ql=query[i].l, qr=query[i].r;
        idx = query[i].idx;
        while(ql&lt;l) Add(--l,0);
        while(r&lt;qr) Add(++r,1);
        while(l&lt;ql) Remove(l++,0);
        while(qr&lt;r) Remove(r--,1);
        ans[idx] = GetAnswer();
    }
}
```

### Example

Consider counting the number of distinct elements in a range.

```cpp
const int RANGE;
int A[N], cnt[RANGE], ans[Q];
int distinct;

void Add(int x){ if(!cnt[A[x]]) distinct++; cnt[A[x]]++; }
void Remove(int x){ cnt[A[x]]--; if(!cnt[A[x]]) distinct--; }
int GetAnswer(){ return distinct; }
```</content><author><name>Jiho Jun</name><email>pianoforte0203@gmail.com</email></author><category term="computer-science" /><category term="algorithms" /><summary type="html"></summary></entry><entry><title type="html">Mertens Trick</title><link href="http://localhost:4000/computer-science/mertens-trick.html" rel="alternate" type="text/html" title="Mertens Trick" /><published>2025-11-11T00:00:00+09:00</published><updated>2025-11-11T00:00:00+09:00</updated><id>http://localhost:4000/computer-science/mertens-trick</id><content type="html" xml:base="http://localhost:4000/computer-science/mertens-trick.html">&lt;!--more--&gt;
* this unordered seed list will be replaced by the toc
{:toc}</content><author><name>Jiho Jun</name><email>pianoforte0203@gmail.com</email></author><category term="computer-science" /><category term="algorithms" /><summary type="html"></summary></entry></feed>