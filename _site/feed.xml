<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2025-06-25T06:36:15+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Jiho’s Blog</title><subtitle>noting down my thoughts and experiences
</subtitle><author><name>Jiho Jun</name><email>pianoforte0203@gmail.com</email></author><entry><title type="html">Continuity</title><link href="http://localhost:4000/mathematics/limits-involving-infinity.html" rel="alternate" type="text/html" title="Continuity" /><published>2025-06-25T00:00:00+09:00</published><updated>2025-06-25T00:00:00+09:00</updated><id>http://localhost:4000/mathematics/limits-involving-infinity</id><content type="html" xml:base="http://localhost:4000/mathematics/limits-involving-infinity.html">&lt;!--more--&gt;

&lt;p&gt;##&lt;/p&gt;</content><author><name>Jiho Jun</name><email>pianoforte0203@gmail.com</email></author><category term="mathematics" /><category term="calculus" /><summary type="html"></summary></entry><entry><title type="html">Random Variables and Distribution Functions</title><link href="http://localhost:4000/mathematics/random-variables-and-distribution-functions.html" rel="alternate" type="text/html" title="Random Variables and Distribution Functions" /><published>2025-06-25T00:00:00+09:00</published><updated>2025-06-25T00:00:00+09:00</updated><id>http://localhost:4000/mathematics/random-variables-and-distribution-functions</id><content type="html" xml:base="http://localhost:4000/mathematics/random-variables-and-distribution-functions.html">&lt;!--more--&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#random-variables&quot; id=&quot;markdown-toc-random-variables&quot;&gt;Random Variables&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#distribution-functions&quot; id=&quot;markdown-toc-distribution-functions&quot;&gt;Distribution Functions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;random-variables&quot;&gt;Random Variables&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;random variable&lt;/strong&gt;  is a function that assigns a real number to each outcome in a sample space.
$X: S \to \mathbb{R}$ is a most common notation for a random variable, where $S$ is the sample space.&lt;/p&gt;

&lt;p&gt;Suppose we have a sample space $S = \set{s_1, s_2, \ldots, s_n}$.
Then a random variable $X$ can be defined as a function that maps each outcome $s_i$ to a real number.
\[
X: S \to \mathbb{R}, X(S) = \mathscr{X} = \set{x_1, x_2, \ldots, x_m}
\]
Thus, we get
\[
P_X(X=x_i) = P(\set{s_j \in S \mid X(s_j) = x_i})
\]
where $P_X$ is the probability measure induced by the random variable $X$.
It is also called the &lt;strong&gt;induced probability function&lt;/strong&gt; on $\mathscr{X}$,
and we can easily check that it satisfies the Kolmogorov axioms.
Therefore, in most cases, we simply write $P(X=x_i)$ instead of $P_X(X=x_i)$.&lt;/p&gt;

&lt;h2 id=&quot;distribution-functions&quot;&gt;Distribution Functions&lt;/h2&gt;</content><author><name>Jiho Jun</name><email>pianoforte0203@gmail.com</email></author><category term="mathematics" /><category term="statistics" /><summary type="html"></summary></entry><entry><title type="html">Conditional Probability and Independence</title><link href="http://localhost:4000/mathematics/conditional-probability-and-independence.html" rel="alternate" type="text/html" title="Conditional Probability and Independence" /><published>2025-06-25T00:00:00+09:00</published><updated>2025-06-25T00:00:00+09:00</updated><id>http://localhost:4000/mathematics/conditional-probability-and-independence</id><content type="html" xml:base="http://localhost:4000/mathematics/conditional-probability-and-independence.html">&lt;!--more--&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#conditional-probability&quot; id=&quot;markdown-toc-conditional-probability&quot;&gt;Conditional Probability&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#bayes-theorem&quot; id=&quot;markdown-toc-bayes-theorem&quot;&gt;Bayes’ Theorem&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#independence&quot; id=&quot;markdown-toc-independence&quot;&gt;Independence&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#mutually-independent-events&quot; id=&quot;markdown-toc-mutually-independent-events&quot;&gt;Mutually Independent Events&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;conditional-probability&quot;&gt;Conditional Probability&lt;/h2&gt;

&lt;p&gt;If $A$ and $B$ are two events (where $B$ is not an empty event), the &lt;strong&gt;conditional probability&lt;/strong&gt; of $A$ given $B$ is defined as the probability of $A$ occurring under the condition that $B$ has occurred.
\[
P(A | B) = \frac{P(A \cap B)}{P(B)}
\]&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$ P(A| A) = 1$&lt;/li&gt;
  &lt;li&gt;If $A$ and $B$ are disjoint, $P(A| B) = P(B| A) = 0$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We can obtain the following equation.
\[
P(A \cap B) = P(A | B) P(B) = P(B | A) P(A)
\]&lt;/p&gt;

&lt;h3 id=&quot;bayes-theorem&quot;&gt;Bayes’ Theorem&lt;/h3&gt;

&lt;p&gt;Bayes’ theorem relates the conditional probabilities of two events $A$ and $B$.
\[
P(A | B) = \frac{P(B | A) P(A)}{P(B)}
\]&lt;/p&gt;

&lt;p&gt;We can also use its extended form. Let $\set{A_i}_{i\in I}$ be a partition of the sample space, and $B$ be any non-empty event.
Then,
\[
P(A_i | B) = \frac{P(B | A_i) P(A_i)}{\dps \sum_{j \in I} P(B | A_j) P(A_j)}
\]
is true. Bayes’ theorem is useful when we want to update our beliefs about the probability of an event based on new evidence.&lt;/p&gt;

&lt;h2 id=&quot;independence&quot;&gt;Independence&lt;/h2&gt;
&lt;p&gt;Two events $A$ and $B$ are said to be &lt;strong&gt;independent&lt;/strong&gt; if the occurrence of one does not affect the probability of the other.
This is mathematically defined as:
\[
P(A \cap B) = P(A) P(B)
\]
If $A$ and $B$ are independent, then:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$P(A | B) = P(A)$&lt;/li&gt;
  &lt;li&gt;$P(B | A) = P(B)$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Following paris of events are also independent:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$A$ and $B^\complement$&lt;/li&gt;
  &lt;li&gt;$A^\complement$ and $B$&lt;/li&gt;
  &lt;li&gt;$A^\complement$ and $B^\complement$&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;mutually-independent-events&quot;&gt;Mutually Independent Events&lt;/h3&gt;

&lt;p&gt;A collection of events $\set{A_i}_{i \in I}$ is said to be &lt;strong&gt;mutually independent&lt;/strong&gt;
if for every finite subset $J \subseteq I$,
\[
P\left(\bigcap_{j \in J} A_j\right) = \prod_{j \in J} P(A_j)
\]&lt;/p&gt;</content><author><name>Jiho Jun</name><email>pianoforte0203@gmail.com</email></author><category term="mathematics" /><category term="statistics" /><summary type="html"></summary></entry><entry><title type="html">Basic Probability Theory</title><link href="http://localhost:4000/mathematics/basic-probability-theory.html" rel="alternate" type="text/html" title="Basic Probability Theory" /><published>2025-06-23T00:00:00+09:00</published><updated>2025-06-23T00:00:00+09:00</updated><id>http://localhost:4000/mathematics/basic-probability-theory</id><content type="html" xml:base="http://localhost:4000/mathematics/basic-probability-theory.html">&lt;!--more--&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#axiomatic-foundations-of-probability&quot; id=&quot;markdown-toc-axiomatic-foundations-of-probability&quot;&gt;Axiomatic Foundations of Probability&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#sigma-algebra&quot; id=&quot;markdown-toc-sigma-algebra&quot;&gt;Sigma-Algebra&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#probability-function&quot; id=&quot;markdown-toc-probability-function&quot;&gt;Probability Function&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#theorems&quot; id=&quot;markdown-toc-theorems&quot;&gt;Theorems&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#1&quot; id=&quot;markdown-toc-1&quot;&gt;1&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#2&quot; id=&quot;markdown-toc-2&quot;&gt;2&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#3&quot; id=&quot;markdown-toc-3&quot;&gt;3&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#4&quot; id=&quot;markdown-toc-4&quot;&gt;4&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#5bonferronis-inequality&quot; id=&quot;markdown-toc-5bonferronis-inequality&quot;&gt;5(Bonferroni’s Inequality)&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;axiomatic-foundations-of-probability&quot;&gt;Axiomatic Foundations of Probability&lt;/h2&gt;

&lt;p&gt;When an experiment is performed, the realization of the experiment is an outcome in the sample space.
If the experiment is repeated, the outcomes may vary.
The &lt;strong&gt;probability&lt;/strong&gt; of an event is a measure of how likely that event is to occur.&lt;/p&gt;

&lt;h3 id=&quot;sigma-algebra&quot;&gt;Sigma-Algebra&lt;/h3&gt;

&lt;p&gt;A collection of subsets, of a sample space $S$ is called a &lt;strong&gt;sigma-algebra&lt;/strong&gt;(or &lt;em&gt;Borel field&lt;/em&gt;), denoted by $\mathscr{B}$, if it satisfies the following properties:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$\emptyset \in \mathscr{B}$&lt;/li&gt;
  &lt;li&gt;$A \in \mathscr{B} \implies A^\complement \in \mathscr{B}$&lt;/li&gt;
  &lt;li&gt;$A_i \in \mathscr{B} \; (i \in I) \implies \bigcup_{i \in I} A_i \in \mathscr{B}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;By the second and third properties and the De Morgan’s laws, we can also conclude that&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$A_i \in \mathscr{B} \; (i \in I) \implies \bigcap_{i \in I} A_i \in \mathscr{B}$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Associated with sample space $S$, we can have many different sigma-algebras.
For example, the collection of the two sets ${\emptyset, S}$ is a sigma-algebra, called the &lt;strong&gt;trivial sigma-algebra&lt;/strong&gt;.
The largest sigma-algebra associated with $S$ is the collection of all subsets of $S$, called the &lt;strong&gt;power set&lt;/strong&gt; of $S$, denoted by $\mathcal{P}(S)$.&lt;/p&gt;

&lt;h3 id=&quot;probability-function&quot;&gt;Probability Function&lt;/h3&gt;

&lt;p&gt;A &lt;strong&gt;probability function&lt;/strong&gt; is a function $P: \mathscr{B} \to \mathbb{R}$ that satisfies the following properties:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$\forall A\in \mathscr{B}: \;P(A) \ge 0$&lt;/li&gt;
  &lt;li&gt;$P(S) = 1$&lt;/li&gt;
  &lt;li&gt;If $\set{A_i}_{i \in I} \subseteq \mathscr{B}$ are pairwise disjoint, then
\[
P\left(\bigcup_{i \in I} A_i\right) = \sum_{i \in I} P(A_i)
\]&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The three properties above are called the &lt;strong&gt;Kolmogorov axioms&lt;/strong&gt; of probability.
Any funcion $P$ that satisfies these axioms is called a probability function.&lt;/p&gt;

&lt;h2 id=&quot;theorems&quot;&gt;Theorems&lt;/h2&gt;

&lt;h3 id=&quot;1&quot;&gt;1&lt;/h3&gt;

&lt;p&gt;Let $S=\set{s_1, \cdots, s_n}$ be a finite sample space and $\mathscr{B}$ be any sigma-algebra on $S$.
Let $p_1, \cdots, p_n$ be non-negative real numbers such that $\sum_{i=1}^n p_i = 1$.
Then there exists a unique probability function $P: \mathscr{B} \to \mathbb{R}$ such that
\[
P(A) = \sum_{\set{i \mid s_i \in A}} p_i
\]
This also remains true if $S$ is countably infinite.&lt;/p&gt;

&lt;h3 id=&quot;2&quot;&gt;2&lt;/h3&gt;

&lt;p&gt;If $P$ is a probability function on a sigma-algebra $\mathscr{B}$, then for any $A \in \mathscr{B}$, we have:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$P(\emptyset) = 0$&lt;/li&gt;
  &lt;li&gt;$P(A) \le 1$&lt;/li&gt;
  &lt;li&gt;$P(A^\complement) = 1 - P(A)$&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3&quot;&gt;3&lt;/h3&gt;

&lt;p&gt;If $P$ is a probability function on a sigma-algebra $\mathscr{B}$, then for any $A, B \in \mathscr{B}$, we have:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$P(B\cap A^\complement) = P(B) - P(A\cap B)$&lt;/li&gt;
  &lt;li&gt;$P(A\cup B) = P(A) + P(B) - P(A\cap B)$&lt;/li&gt;
  &lt;li&gt;$A \subseteq B \implies P(A) \le P(B)$&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4&quot;&gt;4&lt;/h3&gt;

&lt;p&gt;If $P$ is a probability function on a sample space $S$ with a sigma-algebra $\mathscr{B}$, then for any partition
$\set{C_i}_{i \in I}$ of $S$ and for any events $\set{A_i}_{i \in I} \subseteq \mathscr{B}$, we have:
1.
\[
P(A) = \sum_{i \in I} P(A\cap C_i)
\]&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Boole’s Inequality:
\[
P\left (\bigcup_{i \in I} A_i\right) \leq \sum_{i \in I} P(A_i)
\]&lt;/li&gt;
&lt;/ol&gt;

&lt;details&gt;
  &lt;summary&gt; Proof of 1 &lt;/summary&gt;
  &lt;p&gt;Since $\set{C_i}_{i \in I}$ is a partition of $S$,
\[
A = A \cup S = A \cup \left(\bigcup_{i \in I} C_i\right) = \bigcup_{i \in I} (A\cap C_i)
\]
Thus, by the third property of the probability function,
\[
P(A) = P\left(\bigcup_{i \in I} (A\cap C_i)\right) = \sum_{i \in I} P(A\cap C_i)
\]&lt;/p&gt;
&lt;/details&gt;
&lt;details&gt;
  &lt;summary&gt; Proof of 2 &lt;/summary&gt;
  &lt;p&gt;Let $I = \set{1, 2, \cdots, n}$ and here $I$ is countable.
Let’s construct a disjoint collection as follows:
\[
A_1^\ast = A_1, \quad A_i^\ast = A_i \setminus \bigcup_{j=1}^{i-1} A_j
\]
Then, we have
\[
P\left(\bigcup_{i=1}^n A_i\right) = P\left(\bigcup_{i=1}^n A_i^\ast\right) = \sum_{i=1}^n P(A_i^\ast)
\]
Since $A_i^\ast \subseteq A_i$, we have $P(A_i^\ast) \leq P(A_i)$.
Thus,
\[
P\left(\bigcup_{i=1}^n A_i\right) \leq \sum_{i=1}^n P(A_i)
\]&lt;/p&gt;
&lt;/details&gt;

&lt;h3 id=&quot;5bonferronis-inequality&quot;&gt;5(Bonferroni’s Inequality)&lt;/h3&gt;

&lt;p&gt;\[
P\left(\bigcup_{i=1}^n A_i\right) \leq \sum_{i=1}^n P(A_i) - (n-1)
\]&lt;/p&gt;

&lt;details&gt;
  &lt;summary&gt; Proof &lt;/summary&gt;
  &lt;p&gt;We can use the Boole’s Inequality to prove this.
\[
P\left( \bigcup_{i=1}^n A_i^\complement \right) \leq \sum_{i=1}^n P(A_i^\complement)
\]
Using the theorem 2, we have
\[
1 - P\left( \bigcup_{i=1}^n A_i \right) \leq n - \sum_{i=1}^n P(A_i)
\]&lt;/p&gt;
&lt;/details&gt;</content><author><name>Jiho Jun</name><email>pianoforte0203@gmail.com</email></author><category term="mathematics" /><category term="statistics" /><summary type="html"></summary></entry><entry><title type="html">Continuity</title><link href="http://localhost:4000/mathematics/continuity-of-a-function.html" rel="alternate" type="text/html" title="Continuity" /><published>2025-05-26T00:00:00+09:00</published><updated>2025-05-26T00:00:00+09:00</updated><id>http://localhost:4000/mathematics/continuity-of-a-function</id><content type="html" xml:base="http://localhost:4000/mathematics/continuity-of-a-function.html">&lt;!--more--&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#continuity-at-a-point&quot; id=&quot;markdown-toc-continuity-at-a-point&quot;&gt;Continuity at a Point&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#continuity-test&quot; id=&quot;markdown-toc-continuity-test&quot;&gt;Continuity Test&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#types-of-discontinuities&quot; id=&quot;markdown-toc-types-of-discontinuities&quot;&gt;Types of Discontinuities&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#continuous-functions&quot; id=&quot;markdown-toc-continuous-functions&quot;&gt;Continuous Functions&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#properties-of-continuous-functions&quot; id=&quot;markdown-toc-properties-of-continuous-functions&quot;&gt;Properties of Continuous Functions&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#limits-of-continuous-functions&quot; id=&quot;markdown-toc-limits-of-continuous-functions&quot;&gt;Limits of Continuous Functions&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#continuity-of-compositions-of-functions&quot; id=&quot;markdown-toc-continuity-of-compositions-of-functions&quot;&gt;Continuity of Compositions of Functions&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#intermediate-value-theorem&quot; id=&quot;markdown-toc-intermediate-value-theorem&quot;&gt;Intermediate Value Theorem&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#continuous-extension&quot; id=&quot;markdown-toc-continuous-extension&quot;&gt;Continuous Extension&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;continuity-at-a-point&quot;&gt;Continuity at a Point&lt;/h2&gt;

&lt;p&gt;Let $a$ be a point that is either an interior point or an endpoint of the domain of a function $f$.
The function $f$ is said to be &lt;strong&gt;continuous at $a$&lt;/strong&gt; if&lt;/p&gt;

&lt;p&gt;\[
\lim_{x \to a} f(x) = f(a)
\]&lt;/p&gt;

&lt;p&gt;The function is said to be &lt;strong&gt;right-continuous at $a$ (or continuous from the right)&lt;/strong&gt; if&lt;/p&gt;

&lt;p&gt;\[
\lim_{x \to a^+} f(x) = f(a)
\]&lt;/p&gt;

&lt;p&gt;The function is said to be &lt;strong&gt;left-continuous at $a$ (or continuous from the left)&lt;/strong&gt; if&lt;/p&gt;

&lt;p&gt;\[
\lim_{x \to a^-} f(x) = f(a)
\]&lt;/p&gt;

&lt;p&gt;We say that $f$ is &lt;strong&gt;continuous on an interval&lt;/strong&gt; if it is continuous at every point in that interval.
Specifically, if $f$ is continuous at every point in the open interval $(a, b)$, we say that $f$ is continuous on $(a, b)$.
We need a slightly different definition for the closed interval $[a, b]$.
We say that $f$ is continuous on $[a, b]$ if it is continuous at every point in the open interval $(a, b)$ and also right-continuous at $a$ and left-continuous at $b$.
If a function is not continuous at a point $c$ of its domain, we say that $f$ is &lt;strong&gt;discontinuous at $c$&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;continuity-test&quot;&gt;Continuity Test&lt;/h3&gt;

&lt;p&gt;A function $f$ is continuous at a point $a$ if and only if the following three conditions are satisfied:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;$f(a)$ is defined (i.e., $a$ is in the domain of $f$).&lt;/li&gt;
  &lt;li&gt;The limit $\lim_{x \to a} f(x)$ exists.&lt;/li&gt;
  &lt;li&gt;The limit $\lim_{x \to a} f(x)$ is equal to $f(a)$.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;types-of-discontinuities&quot;&gt;Types of Discontinuities&lt;/h2&gt;

&lt;p&gt;A function can be discontinuous at a point for several reasons, leading to different types of discontinuities:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Removable Discontinuity&lt;/strong&gt;: This occurs when the limit exists at a point, but the function is either not defined at that point or is defined to be a different value than the limit.
    &lt;ul&gt;
      &lt;li&gt;ex) sinc function: $f(x) = \sin x/x$ is discontinuous at $x = 0$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Jump Discontinuity&lt;/strong&gt;: This occurs when the left-hand limit and right-hand limit at a point exist but are not equal.
    &lt;ul&gt;
      &lt;li&gt;ex) step function: $f(x) = \lfloor x \rfloor$ is discontinuous at every integer&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Infinite Discontinuity&lt;/strong&gt;: This occurs when the function approaches infinity or negative infinity as it approaches a point.
    &lt;ul&gt;
      &lt;li&gt;ex) $f(x) = 1/x$ is discontinuous at $x = 0$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Oscillating Discontinuity&lt;/strong&gt;: This occurs when the function oscillates infinitely as it approaches a point, preventing the limit from existing.
    &lt;ul&gt;
      &lt;li&gt;ex) $f(x) = \sin(1/x)$ as $x$ approaches 0&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Essential Discontinuity&lt;/strong&gt;: This is a more general term that can refer to any discontinuity that does not fit neatly into the other categories, often involving complex behavior of the function.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;continuous-functions&quot;&gt;Continuous Functions&lt;/h2&gt;

&lt;p&gt;We define a &lt;strong&gt;continuous function&lt;/strong&gt; as a function that is continuous at every point in its domain.
If a function is discontinuous at even one point, it is not considered continuous.&lt;/p&gt;

&lt;h3 id=&quot;properties-of-continuous-functions&quot;&gt;Properties of Continuous Functions&lt;/h3&gt;

&lt;p&gt;If the function $f$ and $g$ are continuous at $a$, then the following properties hold:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Sums&lt;/strong&gt;: $f + g$ is continuous at $a$.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Differences&lt;/strong&gt;: $f - g$ is continuous at $a$.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Constant Multiples&lt;/strong&gt;: $c \cdot f$ is continuous at $a$ for any constant $c$.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Products&lt;/strong&gt;: $f \cdot g$ is continuous at $a$.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Quotients&lt;/strong&gt;: $f/g$ is continuous at $a$ if $g(a) \neq 0$.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Powers&lt;/strong&gt;: $f^n$ is continuous at $a$ for any integer $n$.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Roots&lt;/strong&gt;: $\sqrt[n]{f}$ is continuous at $a$ if $f(a) \geq 0$ for even $n$.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;These properties are easily verified using the &lt;a href=&quot;https://berryjune07.github.io/mathematics/a-limit-of-a-function.html#limit-laws&quot;&gt;limit properties&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;limits-of-continuous-functions&quot;&gt;Limits of Continuous Functions&lt;/h3&gt;

&lt;p&gt;If $\lim_{x \to a} f(x) = b$ and $g$ is continuous at $b$, then the limit of the composition is given by:&lt;/p&gt;

&lt;p&gt;\[
\lim_{x \to a} g(f(x)) = g(b) = g\left( \lim_{x \to a} f(x) \right)
\]&lt;/p&gt;

&lt;p&gt;This means that limit operators can be commuted with continuous functions. Let’s prove it using the epsilon-delta strategy.&lt;/p&gt;

&lt;p&gt;\[
\begin{align*}
&amp;amp; \forall \varepsilon&amp;gt;0, \exists \delta_1,\delta_2&amp;gt;0 \quad \text{s.t.} \quad
\begin{cases}
\dps 0&amp;lt;|y-b|&amp;lt;\delta_1 \implies |g(y)-g(b)|&amp;lt;\varepsilon \nl
\dps 0&amp;lt;|x-a|&amp;lt;\delta_2 \implies |f(x)-b|&amp;lt;\delta_1
\end{cases} \nl
&amp;amp; \text{set} \;\; y=f(x) \nl \nl
&amp;amp; 0&amp;lt;|x-a|&amp;lt;\delta_2 \implies |g(f(x)) - g(b)| &amp;lt; \varepsilon \nl
&amp;amp; \therefore \lim_{x \to a} g(f(x)) = g(b) = g\left( \lim_{x \to a} f(x) \right)
\end{align*}
\]&lt;/p&gt;

&lt;h3 id=&quot;continuity-of-compositions-of-functions&quot;&gt;Continuity of Compositions of Functions&lt;/h3&gt;

&lt;p&gt;If $f$ is continuous at $a$ and $g$ is continuous at $f(a)$, then the composition $g \circ f$ is continuous at $a$.&lt;/p&gt;

&lt;p&gt;\[
\lim_{x \to a} f(x) = f(a), \;\; \lim_{y \to f(a)} g(y) = g(f(a)) \implies \lim_{x \to a} g(f(x)) = g(f(a))
\]&lt;/p&gt;

&lt;h2 id=&quot;intermediate-value-theorem&quot;&gt;Intermediate Value Theorem&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;Intermediate Value Theorem(IVT)&lt;/strong&gt; states that if $f$ is continuous on the closed interval $[a, b]$ and $y_0$ is any value between $f(a)$ and $f(b)$, then there exists at least one point $c$ in the interval $(a, b)$ such that $f(c) = y_0$.
Geometrically, this means that the graph of $f$ must cross the horizontal line $y = y_0$ at least once in the interval $(a, b)$.&lt;/p&gt;

&lt;p&gt;Let’s state the theorem formally:
If $f:[a,b]\to\mathbb{R}$ is continuous,&lt;/p&gt;

&lt;p&gt;\[
\forall y_0 \in \left( \min \{f(a),f(b)\}, \max \{f(a),f(b)\} \right),\; \exists c \in (a,b) \quad \text{s.t.} \quad f(c) = y_0
\]&lt;/p&gt;

&lt;p&gt;or can also be stated as:&lt;/p&gt;

&lt;p&gt;\[
\left[\min \{f(a),f(b)\}, \max \{f(a),f(b)\} \right] \subseteq f([a,b])
\]&lt;/p&gt;

&lt;p&gt;where $f([a,b])$ is also a closed interval. IVT is a powerful tool in calculus, especially for proving the existence of roots of equations and understanding the behavior of continuous functions.
Its proof relies on the completeness property of the real numbers.&lt;/p&gt;

&lt;details&gt;
  &lt;summary&gt; Proof &lt;/summary&gt;
  &lt;p&gt;WLOG assume $f(a) &amp;lt; f(b)$, then $f(a) &amp;lt; y_0 &amp;lt; f(b)$. For an arbitrary $y_0$, define the set&lt;/p&gt;

  &lt;p&gt;\[
E = \Set{ x\in [a,b] \mid f(x) &amp;lt; y_0 }
\]
Then $E$ is non-empty since $a \in E$ and $E$ is bounded above by $b$. Therefore, by the completeness property of the real numbers, $E$ has a least upper bound $c = \sup E$.
Since $f$ is continuous at $c$, we have $\delta &amp;gt; 0$ which satisfies
\[
a\le x &amp;lt; a+\delta \implies f(x) &amp;lt; y_0 \nl
b-\delta &amp;lt; x \le b \implies f(x) &amp;gt; y_0
\]
Therefore, $a&amp;lt;c&amp;lt;b$, and let’s prove by contradiction that $f(c) = y_0$.
Assume $f(c) &amp;gt; y_0$, then there exists $\eta&amp;gt;0$ such that
\[
c-\eta &amp;lt; x &amp;lt; c+\eta \implies f(x) &amp;gt; y_0
\]
Then $c-\eta$ is an upper bound of $E$, which contradicts the fact that $c$ is the least upper bound of $E$.
If $f(c) &amp;lt; y_0$, then there exists $\eta&amp;gt;0$ such that
\[
c-\eta &amp;lt; x &amp;lt; c+\eta \implies f(x) &amp;lt; y_0
\]
Then $c+\eta/2 \in E$, which contradicts the fact that $c$ is the least upper bound of $E$.
Therefore, finally we conclude that $f(c) = y_0$.&lt;/p&gt;
&lt;/details&gt;

&lt;h2 id=&quot;continuous-extension&quot;&gt;Continuous Extension&lt;/h2&gt;

&lt;p&gt;A function $f$ is said to have a &lt;strong&gt;continuous extension&lt;/strong&gt; at a point $a$ if there exists a function $g$ such that:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$g$ is continuous at $a$,&lt;/li&gt;
  &lt;li&gt;$g(x) = f(x)$ for all $x$ in the domain of $f$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In other words, $g$ extends $f$ to include the point $a$ while preserving continuity.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$g(a) = \lim_{x \to a} f(x)$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The sinc function is a classic example of a function that has a continuous extension at $x = 0$.
The continuous extension of the sinc function is defined as:
\[
g(x) = \begin{cases}
\sin x / x &amp;amp;; x \neq 0 \nl
1 &amp;amp;; x = 0
\end{cases}
\]&lt;/p&gt;</content><author><name>Jiho Jun</name><email>pianoforte0203@gmail.com</email></author><category term="mathematics" /><category term="calculus" /><summary type="html"></summary></entry><entry><title type="html">One-Sided Limits</title><link href="http://localhost:4000/mathematics/one-sided-limits.html" rel="alternate" type="text/html" title="One-Sided Limits" /><published>2025-05-22T00:00:00+09:00</published><updated>2025-05-22T00:00:00+09:00</updated><id>http://localhost:4000/mathematics/one-sided-limits</id><content type="html" xml:base="http://localhost:4000/mathematics/one-sided-limits.html">&lt;!--more--&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#one-sided-limits&quot; id=&quot;markdown-toc-one-sided-limits&quot;&gt;One-Sided Limits&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#relationship-between-one-sided-limits-and-general-limits&quot; id=&quot;markdown-toc-relationship-between-one-sided-limits-and-general-limits&quot;&gt;Relationship Between One-Sided Limits and General Limits&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;one-sided-limits&quot;&gt;One-Sided Limits&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;one-sided limit&lt;/strong&gt; is a limit that only considers the behavior of a function as it approaches a specific point from one side (either the left or the right).
There are two types of one-sided limits:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Left-Hand Limit&lt;/strong&gt;: The limit of a function as the input approaches a certain value from the left side(values less than the point).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Right-Hand Limit&lt;/strong&gt;: The limit of a function as the input approaches a certain value from the right side(values greater than the point).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;They are defined precisely as follows: Let $f$ be a function defined on an open interval $I$ containing $a$ (except possibly at $a$ itself).
If for every number $\epsilon &amp;gt; 0$, there exists a corresponding number $\delta &amp;gt; 0$ such that &lt;br /&gt;
$a &amp;lt; x &amp;lt; a + \delta \implies |f(x) - L| &amp;lt; \epsilon$, then we write it as
\[
\lim_{x \to a^+} f(x) \quad \text{or} \quad \lim_{x \downarrow a} f(x) \quad \text{or} \quad \lim_{x \searrow a} f(x) = L
\]
or $a - \delta &amp;lt; x &amp;lt; a \implies |f(x) - L| &amp;lt; \epsilon$, then we write it as
\[
\lim_{x \to a^-} f(x) \quad \text{or} \quad \lim_{x \uparrow a} f(x) \quad \text{or} \quad \lim_{x \nearrow a} f(x) = L
\]&lt;/p&gt;

&lt;h2 id=&quot;relationship-between-one-sided-limits-and-general-limits&quot;&gt;Relationship Between One-Sided Limits and General Limits&lt;/h2&gt;

&lt;p&gt;Trivially, if the left-hand limit and right-hand limit of a function at a point are equal, then the general limit exists and is equal to that common value.
\[
\lim_{x \to a} f(x) = L \quad \text{if and only if} \quad \lim_{x \to a^-} f(x) = \lim_{x \to a^+} f(x) = L
\]
This means that if the function approaches the same value from both sides as $x$ approaches $a$, then the limit exists and is equal to that value.
Conversely, if even one of the one-sided limits does not exist or is not equal to the other, then the general limit does not exist.&lt;/p&gt;</content><author><name>Jiho Jun</name><email>pianoforte0203@gmail.com</email></author><category term="mathematics" /><category term="calculus" /><summary type="html"></summary></entry><entry><title type="html">A Limit of a Function</title><link href="http://localhost:4000/mathematics/a-limit-of-a-function.html" rel="alternate" type="text/html" title="A Limit of a Function" /><published>2025-05-12T00:00:00+09:00</published><updated>2025-05-12T00:00:00+09:00</updated><id>http://localhost:4000/mathematics/a-limit-of-a-function</id><content type="html" xml:base="http://localhost:4000/mathematics/a-limit-of-a-function.html">&lt;!--more--&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#definition-of-limit&quot; id=&quot;markdown-toc-definition-of-limit&quot;&gt;Definition of Limit&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#limit-laws&quot; id=&quot;markdown-toc-limit-laws&quot;&gt;Limit Laws&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#proof-of-limit-laws&quot; id=&quot;markdown-toc-proof-of-limit-laws&quot;&gt;Proof of Limit Laws&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#limits-of-polynomials&quot; id=&quot;markdown-toc-limits-of-polynomials&quot;&gt;Limits of Polynomials&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#limits-of-rational-functions&quot; id=&quot;markdown-toc-limits-of-rational-functions&quot;&gt;Limits of Rational Functions&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#sandwich-theorem&quot; id=&quot;markdown-toc-sandwich-theorem&quot;&gt;Sandwich Theorem&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;definition-of-limit&quot;&gt;Definition of Limit&lt;/h2&gt;

&lt;p&gt;Suppose we are watching the values of a function $f(x)$ as $x$ approaches a number $a$,
without actually reaching $a$. This is the basic idea of a limit.
We can define the limit of a function preciselt using the &lt;strong&gt;epsilon-delta definition&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Let $f$ be a function defined on an open interval $I$ containing $a$ (except possibly at $a$ itself).
We say that the limit of $f(x)$ as $x$ approaches $a$ is $L$, and we write&lt;/p&gt;

&lt;p&gt;\[
\lim_{x \to a} f(x) = L
\]&lt;/p&gt;

&lt;p&gt;if for every number $\epsilon &amp;gt; 0$, there exists a corresponding number $\delta &amp;gt; 0$ such that&lt;/p&gt;

&lt;p&gt;\[
0 &amp;lt; |x - a| &amp;lt; \delta \implies |f(x) - L| &amp;lt; \epsilon
\]&lt;/p&gt;

&lt;p&gt;This means that we can make the values of $f(x)$ as close to $L$ as we want by making $x$ sufficiently close to $a$.&lt;/p&gt;

&lt;h2 id=&quot;limit-laws&quot;&gt;Limit Laws&lt;/h2&gt;

&lt;p&gt;If $L,M,c,k$ are real numbers, $n$ is a positive integer, and
\[
\lim_{x \to a} f(x) = L, \quad \lim_{x \to a} g(x) = M
\]
then the following limit laws hold:&lt;/p&gt;

&lt;p&gt;\[
\begin{align*}
\bullet \;&amp;amp; \lim_{x \to a} (f(x) + g(x)) = L + M \nl
\bullet \;&amp;amp; \lim_{x \to a} (f(x) - g(x)) = L - M \nl
\bullet \;&amp;amp; \lim_{x \to a} kf(x) = kL \nl
\bullet \;&amp;amp; \lim_{x \to a} f(x)g(x) = LM \nl
\bullet \;&amp;amp; \lim_{x \to a} \frac{f(x)}{g(x)} = \frac{L}{M} \quad (M \neq 0) \nl
\bullet \;&amp;amp; \lim_{x \to a} f(x)^n = L^n \nl
\bullet \;&amp;amp; \lim_{x \to a} \sqrt[n]{f(x)} = \sqrt[n]{L} \quad (2\mid n \rightarrow L \geq 0)
\end{align*}
\]&lt;/p&gt;

&lt;h3 id=&quot;proof-of-limit-laws&quot;&gt;Proof of Limit Laws&lt;/h3&gt;

&lt;p&gt;The proof of the limit laws is based on the epsilon-delta definition of limits.&lt;/p&gt;

&lt;p&gt;⁣1. $ \lim_{x \to a} (f(x) \pm g(x)) = L \pm M $&lt;/p&gt;
&lt;details&gt;
  &lt;summary&gt; Proof &lt;/summary&gt;
  &lt;p&gt;\[
\begin{align*}
&amp;amp; \forall \varepsilon&amp;gt;0, \exists \delta_1,\delta_2&amp;gt;0 \quad \text{s.t.} \quad
\begin{cases}
\dps 0&amp;lt;|x-a|&amp;lt;\delta_1 \implies |f(x)-L|&amp;lt;\frac{\varepsilon}{2} \nl \nl
\dps 0&amp;lt;|x-a|&amp;lt;\delta_2 \implies |g(x)-M|&amp;lt;\frac{\varepsilon}{2} 
\end{cases} \nl
&amp;amp; \delta = \min(\delta_1,\delta_2) \nl\nl
&amp;amp; \begin{aligned} 0&amp;lt;|x-a|&amp;lt;\delta \implies |f(x)\pm g(x) - (L\pm M)| &amp;amp;\leq |f(x)-L| + |g(x)-M| \nl
&amp;amp;&amp;lt; \frac{\varepsilon}{2} + \frac{\varepsilon}{2} = \varepsilon \end{aligned} \nl
&amp;amp; \therefore \lim_{x \to a} (f(x) \pm g(x)) = L \pm M
\end{align*}
\]&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;⁣2. $ \lim_{x \to a} f(x)g(x) = LM $&lt;/p&gt;
&lt;details&gt;
  &lt;summary&gt; Proof &lt;/summary&gt;
  &lt;p&gt;\[
\begin{align*}
&amp;amp; \forall \varepsilon&amp;gt;0, \exists \delta_1,\delta_2,\delta_3&amp;gt;0 \quad \text{s.t.} \quad
\begin{cases}
\dps 0&amp;lt;|x-a|&amp;lt;\delta_1 \implies |g(x)-M|&amp;lt;\frac{\varepsilon}{2(|L|+1)} \nl \nl
\dps 0&amp;lt;|x-a|&amp;lt;\delta_2 \implies |g(x)-M|&amp;lt;1 \implies |g(x)|&amp;lt;|M|+1 \nl \nl
\dps 0&amp;lt;|x-a|&amp;lt;\delta_3 \implies |f(x)-L|&amp;lt;\frac{\varepsilon}{2(|M|+1)}
\end{cases} \nl
&amp;amp; \delta = \min(\delta_1,\delta_2,\delta_3) \nl\nl
&amp;amp; \begin{aligned} 0&amp;lt;|x-a|&amp;lt;\delta \implies |f(x)g(x) - LM| &amp;amp;\leq |f(x)g(x) - Lg(x)| + |Lg(x) - LM| \nl
&amp;amp;= |f(x) - L||g(x)| + |L||g(x) - M| \nl
&amp;amp;&amp;lt; \frac{\varepsilon}{2(|M|+1)}(|M|+1) + |L|\frac{\varepsilon}{2(|L|+1)} \nl
&amp;amp;\leq \frac{\varepsilon}{2} + \frac{\varepsilon}{2} = \varepsilon \end{aligned} \nl
&amp;amp; \therefore \lim_{x \to a} f(x)g(x) = LM
\end{align*}
\]&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;⁣3. $ \lim_{x \to a} 1/f(x) = 1/L \quad (L \neq 0) $&lt;/p&gt;
&lt;details&gt;
  &lt;summary&gt; Proof &lt;/summary&gt;
  &lt;p&gt;\[
\begin{align*}
&amp;amp; \forall \varepsilon&amp;gt;0, \exists \delta_1,\delta_2&amp;gt;0 \quad \text{s.t.} \quad
\begin{cases}
\dps 0&amp;lt;|x-a|&amp;lt;\delta_1 \implies |f(x)-L|&amp;lt;\frac{|L|}{2} \implies |f(x)|&amp;gt;\frac{|L|}{2} \nl \nl
\dps 0&amp;lt;|x-a|&amp;lt;\delta_2 \implies |f(x)-L|&amp;lt;\frac{|L|^2}{2}\varepsilon
\end{cases} \nl
&amp;amp; \delta = \min(\delta_1,\delta_2) \nl\nl
&amp;amp; \begin{aligned} 0&amp;lt;|x-a|&amp;lt;\delta \implies \left|\frac{1}{f(x)} - \frac{1}{L}\right| &amp;amp;= \left|\frac{f(x) - L}{f(x)L}\right| \nl
&amp;amp;&amp;lt; \frac{|f(x) - L|}{\frac{|L|}{2}|L|} = \frac{2|f(x) - L|}{|L|^2} \nl
&amp;amp;&amp;lt; \frac{2\varepsilon}{|L|^2} \cdot \frac{|L|^2}{2} = \varepsilon \end{aligned} \nl
&amp;amp; \therefore \lim_{x \to a} \frac{1}{f(x)} = \frac{1}{L}
\end{align*}
\]&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;We can prove the other limit laws using the above equations already proved.
The last limit law, $ \lim_{x \to a} \sqrt[n]{f(x)} = \sqrt[n]{L} $, is only the exception.
Knowledge about continuous functions is required to prove it, so we will not prove it here.&lt;/p&gt;

&lt;h3 id=&quot;limits-of-polynomials&quot;&gt;Limits of Polynomials&lt;/h3&gt;

&lt;p&gt;Let $f(x)\in \mathbb{R}[x]$ be a polynomial function.&lt;/p&gt;

&lt;p&gt;\[
\lim_{x \to a} f(x) = f(a)
\]&lt;/p&gt;

&lt;p&gt;We can prove this by a simple induction.&lt;/p&gt;

&lt;h3 id=&quot;limits-of-rational-functions&quot;&gt;Limits of Rational Functions&lt;/h3&gt;

&lt;p&gt;Let $P(x)$ and $Q(x)$ be polynomials such that $Q(a) \neq 0$.&lt;/p&gt;

&lt;p&gt;\[
\lim_{x \to a} \frac{P(x)}{Q(x)} = \frac{P(a)}{Q(a)}
\]&lt;/p&gt;

&lt;p&gt;It is trivial by the quotient law.&lt;/p&gt;

&lt;h3 id=&quot;sandwich-theorem&quot;&gt;Sandwich Theorem&lt;/h3&gt;

&lt;p&gt;Suppose that $g(x) \leq f(x) \leq h(x)$ for all $x$ in some open interval containing $a$, except possibly at $a$ itself.
Then the following holds:&lt;/p&gt;

&lt;p&gt;\[
\lim_{x \to a} g(x) = \lim_{x \to a} h(x) = L \implies \lim_{x \to a} f(x) = L
\]&lt;/p&gt;

&lt;p&gt;It is called the &lt;strong&gt;sandwich theorem&lt;/strong&gt; because the function $f(x)$ is caught between $g(x)$ and $h(x)$ just like a ham between two slices of bread.
Thus, it is also called the &lt;strong&gt;squeeze theorem&lt;/strong&gt;. Lets’ prove it.&lt;/p&gt;

&lt;p&gt;\[
\begin{align*}
&amp;amp; \forall \varepsilon&amp;gt;0, \exists \delta_1,\delta_2&amp;gt;0 \quad \text{s.t.} \quad
\begin{cases}
\dps 0&amp;lt;|x-a|&amp;lt;\delta_1 \implies |g(x)-L|&amp;lt;\varepsilon \implies L-\varepsilon&amp;lt;g(x)&amp;lt;L+\varepsilon \nl
\dps 0&amp;lt;|x-a|&amp;lt;\delta_2 \implies |h(x)-L|&amp;lt;\varepsilon \implies L-\varepsilon&amp;lt;h(x)&amp;lt;L+\varepsilon
\end{cases} \nl
&amp;amp; \delta = \min(\delta_1,\delta_2) \nl\nl
&amp;amp; 0&amp;lt;|x-a|&amp;lt;\delta \implies L-\varepsilon &amp;lt; g(x) \le f(x) \le h(x)&amp;lt;L+\varepsilon
\implies |f(x) - L| &amp;lt; \varepsilon \nl
&amp;amp; \therefore \lim_{x \to a} f(x) = L
\end{align*}
\]&lt;/p&gt;

&lt;p&gt;Sandwich theorem is very useful to find the specific limit of a function.&lt;/p&gt;</content><author><name>Jiho Jun</name><email>pianoforte0203@gmail.com</email></author><category term="mathematics" /><category term="calculus" /><summary type="html"></summary></entry><entry><title type="html">Combining Functions</title><link href="http://localhost:4000/mathematics/combining-functions.html" rel="alternate" type="text/html" title="Combining Functions" /><published>2025-04-30T00:00:00+09:00</published><updated>2025-04-30T00:00:00+09:00</updated><id>http://localhost:4000/mathematics/combining-functions</id><content type="html" xml:base="http://localhost:4000/mathematics/combining-functions.html">&lt;!--more--&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#basic-operations-on-functions&quot; id=&quot;markdown-toc-basic-operations-on-functions&quot;&gt;Basic Operations on Functions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#composition-of-functions&quot; id=&quot;markdown-toc-composition-of-functions&quot;&gt;Composition of Functions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#shifting&quot; id=&quot;markdown-toc-shifting&quot;&gt;Shifting&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#scaling-and-reflection&quot; id=&quot;markdown-toc-scaling-and-reflection&quot;&gt;Scaling and Reflection&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;basic-operations-on-functions&quot;&gt;Basic Operations on Functions&lt;/h2&gt;

&lt;p&gt;Like numbers, functions can be combined using basic operations such as addition, subtraction, multiplication, and division.
If $f$ and $g$ are two functions, we can define new functions on their common domain $D(f) \cap D(g)$ as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Addition&lt;/strong&gt;: $(f+g)(x) = f(x) + g(x)$&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Subtraction&lt;/strong&gt;: $(f-g)(x) = f(x) - g(x)$&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Multiplication&lt;/strong&gt;: $(fg)(x) = f(x)g(x)$&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Division&lt;/strong&gt;: $(f/g)(x) = \frac{f(x)}{g(x)}$ for $g(x) \neq 0$&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;composition-of-functions&quot;&gt;Composition of Functions&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;composition&lt;/strong&gt; of two functions $f$ and $g$ is a new function defined by applying one function to the result of the other.
It can only be performed when the range of the first function is a subset of the domain of the second function,
i.e. $g(X) \subset D(f)$.
The composition of $f$ and $g$ is denoted by $f \circ g$ and is defined as:&lt;/p&gt;

&lt;p&gt;\[
f \circ g (x) = f(g(x))
\]&lt;/p&gt;

&lt;p class=&quot;centered&quot;&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/Example_for_a_composition_of_two_functions.svg/1703px-Example_for_a_composition_of_two_functions.svg.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;figcaption&quot;&gt;A diagram showing the composition of two functions&lt;/p&gt;

&lt;h2 id=&quot;shifting&quot;&gt;Shifting&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;shifting&lt;/strong&gt; of a function is a transformation that moves the graph of the function in the coordinate plane.
There are two types of shifts: vertical and horizontal.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Vertical Shift&lt;/strong&gt;: $y = f(x) + k$ shifts the graph in the vertical direction.
    &lt;ul&gt;
      &lt;li&gt;If $k &amp;gt; 0$, the graph shifts up.&lt;/li&gt;
      &lt;li&gt;If $k &amp;lt; 0$, the graph shifts down.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Horizontal Shift&lt;/strong&gt;: $y = f(x - h)$ shifts the graph in the horizontal direction.
    &lt;ul&gt;
      &lt;li&gt;If $h &amp;gt; 0$, the graph shifts to the right.&lt;/li&gt;
      &lt;li&gt;If $h &amp;lt; 0$, the graph shifts to the left.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Both types of shifts can also be performed simultaneously.&lt;/p&gt;

&lt;h2 id=&quot;scaling-and-reflection&quot;&gt;Scaling and Reflection&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Scaling&lt;/strong&gt; is a transformation that stretches or compresses the graph of a function in the vertical or horizontal direction.
There also are two types of scaling: vertical and horizontal.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Vertical Scaling&lt;/strong&gt;: $y = kf(x)$ scales the graph vertically.
    &lt;ul&gt;
      &lt;li&gt;If $k &amp;gt; 1$, the graph stretches vertically.&lt;/li&gt;
      &lt;li&gt;If $0 &amp;lt; k &amp;lt; 1$, the graph compresses vertically.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Horizontal Scaling&lt;/strong&gt;: $y = f(kx)$ scales the graph horizontally.
    &lt;ul&gt;
      &lt;li&gt;If $k &amp;gt; 1$, the graph compresses horizontally.&lt;/li&gt;
      &lt;li&gt;If $0 &amp;lt; k &amp;lt; 1$, the graph stretches horizontally.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Reflection&lt;/strong&gt; is a transformation that flips the graph of a function across a line.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Reflection across the x-axis&lt;/strong&gt;: $y = -f(x)$ reflects the graph across the x-axis.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Reflection across the y-axis&lt;/strong&gt;: $y = f(-x)$ reflects the graph across the y-axis.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We can think of the reflection as a special case of scaling, where the scaling factor is exactly $k = -1$.
Scaling for any $k&amp;lt;0$, can be regarded as a reflection followed by a scaling with $|k|$.&lt;/p&gt;</content><author><name>Jiho Jun</name><email>pianoforte0203@gmail.com</email></author><category term="mathematics" /><category term="calculus" /><summary type="html"></summary></entry><entry><title type="html">Periodic and Trigonometric Functions</title><link href="http://localhost:4000/mathematics/periodic-and-trigonometric-functions.html" rel="alternate" type="text/html" title="Periodic and Trigonometric Functions" /><published>2025-04-30T00:00:00+09:00</published><updated>2025-04-30T00:00:00+09:00</updated><id>http://localhost:4000/mathematics/periodic-and-trigonometric-functions</id><content type="html" xml:base="http://localhost:4000/mathematics/periodic-and-trigonometric-functions.html">&lt;!--more--&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#periodic-functions&quot; id=&quot;markdown-toc-periodic-functions&quot;&gt;Periodic Functions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#trigonometric-functions&quot; id=&quot;markdown-toc-trigonometric-functions&quot;&gt;Trigonometric Functions&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#angle-measurement&quot; id=&quot;markdown-toc-angle-measurement&quot;&gt;Angle Measurement&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#sine-and-cosine-functions&quot; id=&quot;markdown-toc-sine-and-cosine-functions&quot;&gt;Sine and Cosine Functions&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#the-six-basic-trigonometric-functions&quot; id=&quot;markdown-toc-the-six-basic-trigonometric-functions&quot;&gt;The Six Basic Trigonometric Functions&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#trigonometrical-identities&quot; id=&quot;markdown-toc-trigonometrical-identities&quot;&gt;Trigonometrical Identities&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#pythagorean-identities&quot; id=&quot;markdown-toc-pythagorean-identities&quot;&gt;Pythagorean Identities&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#angle-addition-identities&quot; id=&quot;markdown-toc-angle-addition-identities&quot;&gt;Angle Addition Identities&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#the-law-of-cosines&quot; id=&quot;markdown-toc-the-law-of-cosines&quot;&gt;The Law of Cosines&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#extra-properties&quot; id=&quot;markdown-toc-extra-properties&quot;&gt;Extra Properties&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;periodic-functions&quot;&gt;Periodic Functions&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;periodic function&lt;/strong&gt; is a function that repeats its values at regular intervals.
The smallest positive value of $p$ such that $f(x + p) = f(x)$ for all $x$ in the domain of $f$ is called the &lt;strong&gt;period&lt;/strong&gt; of the function. (Sometimes, the word “smallest” is omitted)
The period of a periodic function is the length of one complete cycle of the function.
Trigonometric functions are the most common examples of periodic functions.&lt;/p&gt;

&lt;h2 id=&quot;trigonometric-functions&quot;&gt;Trigonometric Functions&lt;/h2&gt;

&lt;h3 id=&quot;angle-measurement&quot;&gt;Angle Measurement&lt;/h3&gt;

&lt;p&gt;Angles are measured in &lt;strong&gt;radians&lt;/strong&gt;. Radians are defined as the ratio of the length of the arc subtended by the angle to the radius of the circle.&lt;/p&gt;

&lt;p&gt;\[
\theta = \frac{s}{r}
\]&lt;/p&gt;

&lt;p&gt;where $\theta$ is the angle in radians, $s$ is the length of the arc, and $r$ is the radius of the circle.
The relationship between degrees and radians is given by:&lt;/p&gt;

&lt;p&gt;\[
\pi \text{ rad} = 180^\circ
\]&lt;/p&gt;

&lt;h3 id=&quot;sine-and-cosine-functions&quot;&gt;Sine and Cosine Functions&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;sine&lt;/strong&gt; and &lt;strong&gt;cosine&lt;/strong&gt; functions can be defined in several ways, typically using the unit circle(geometrical way) or power series(analytical way).
It is convenient to define them using the power series for latter discussions such as differentiation,
but here we will use the unit circle definition for simplicity.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;unit circle&lt;/strong&gt; is a circle with a radius of 1 centered at the origin of the Cartesian coordinate system.
The coordinates of a point on the unit circle can be expressed in terms of the angle $\theta$ as follows,
and thus the sine and cosine functions are defined as:&lt;/p&gt;

&lt;p&gt;\[
x = \cos(\theta), \quad y = \sin(\theta)
\]&lt;/p&gt;

&lt;p class=&quot;centered&quot;&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/8/8f/Unit_circle.svg/1024px-Unit_circle.svg.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;figcaption&quot;&gt;Sine and cosine functions on the unit circle&lt;/p&gt;

&lt;p&gt;The sine and cosine functions are periodic with a period of $2\pi$.&lt;/p&gt;

&lt;h3 id=&quot;the-six-basic-trigonometric-functions&quot;&gt;The Six Basic Trigonometric Functions&lt;/h3&gt;

&lt;p&gt;The six basic trigonometric functions are defined as follows:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Sine&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Cosine&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Tangent&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Cosecant&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Secant&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Cotangent&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Functions&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\sin x$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\cos x$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\tan x = \dfrac{\sin x}{\cos x}$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\csc x = \dfrac{1}{\sin x}$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\sec x = \dfrac{1}{\cos x}$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\cot x = \dfrac{\cos x}{\sin x}$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Domain&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\mathbb{R}$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\mathbb{R}$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\mathbb{R} \setminus \left( \mathbb{Z} + \dfrac{1}{2} \right)\pi$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\mathbb{R} \setminus \mathbb{Z}\pi$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\mathbb{R} \setminus \left( \mathbb{Z} + \dfrac{1}{2} \right)\pi$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\mathbb{R} \setminus \mathbb{Z}\pi$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Range&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$[-1, 1]$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$[-1, 1]$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\mathbb{R}$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\mathbb{R} \setminus (-1,1)$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\mathbb{R} \setminus (-1,1)$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\mathbb{R}$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Period&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$2\pi$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$2\pi$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\pi$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$2\pi$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$2\pi$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\pi$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Symmetry&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Odd&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Even&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Odd&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Odd&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Even&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Odd&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p class=&quot;centered&quot;&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/2/27/Trigonometric_functions_derivation_animation.svg&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;figcaption&quot;&gt;Animation of the six basic trigonometric functions&lt;/p&gt;

&lt;p class=&quot;centered&quot;&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/1/19/Trigonometric_functions.svg/2560px-Trigonometric_functions.svg.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;figcaption&quot;&gt;Graph of the six basic trigonometric functions&lt;/p&gt;

&lt;h2 id=&quot;trigonometrical-identities&quot;&gt;Trigonometrical Identities&lt;/h2&gt;

&lt;h3 id=&quot;pythagorean-identities&quot;&gt;Pythagorean Identities&lt;/h3&gt;

&lt;p&gt;\[
\sin^2 x + \cos^2 x = 1 \nl
\sec^2 x = 1 + \tan^2 x \nl
\csc^2 x = 1 + \cot^2 x
\]&lt;/p&gt;

&lt;h3 id=&quot;angle-addition-identities&quot;&gt;Angle Addition Identities&lt;/h3&gt;

&lt;p&gt;\[
\sin(x + y) = \sin x \cos y + \cos x \sin y \nl
\cos(x + y) = \cos x \cos y - \sin x \sin y \nl
\tan(x + y) = \frac{\tan x + \tan y}{1 - \tan x \tan y}
\]&lt;/p&gt;

&lt;h3 id=&quot;the-law-of-cosines&quot;&gt;The Law of Cosines&lt;/h3&gt;

&lt;p&gt;If $a,b,c$ are the lengths of the sides of a triangle opposite to angles $A,B,C$, respectively, then:&lt;/p&gt;

&lt;p&gt;\[
c^2 = a^2 + b^2 - 2ab \cos C \nl
a^2 = b^2 + c^2 - 2bc \cos A \nl
b^2 = c^2 + a^2 - 2ca \cos B
\]&lt;/p&gt;

&lt;h3 id=&quot;extra-properties&quot;&gt;Extra Properties&lt;/h3&gt;

&lt;p&gt;\[
\abs{ \sin \theta } \leq \abs{ \theta } \leq \abs{ \tan \theta } \quad \left( \abs{ \theta } &amp;lt; \frac{\pi}{2} \right) \nt
0\leq 1 - \cos \theta \leq \frac{ \theta^2 }{2}
\]&lt;/p&gt;

&lt;p&gt;These are very easy to prove, so I will not include the proofs here.&lt;/p&gt;</content><author><name>Jiho Jun</name><email>pianoforte0203@gmail.com</email></author><category term="mathematics" /><category term="calculus" /><summary type="html"></summary></entry><entry><title type="html">Set Theory for Statistics</title><link href="http://localhost:4000/mathematics/set-theory-for-statistics.html" rel="alternate" type="text/html" title="Set Theory for Statistics" /><published>2025-04-18T00:00:00+09:00</published><updated>2025-04-18T00:00:00+09:00</updated><id>http://localhost:4000/mathematics/set-theory-for-statistics</id><content type="html" xml:base="http://localhost:4000/mathematics/set-theory-for-statistics.html">&lt;!--more--&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#sample-space-and-events&quot; id=&quot;markdown-toc-sample-space-and-events&quot;&gt;Sample Space and Events&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#set-relationships-and-operations&quot; id=&quot;markdown-toc-set-relationships-and-operations&quot;&gt;Set Relationships and Operations&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#elementary-identities&quot; id=&quot;markdown-toc-elementary-identities&quot;&gt;Elementary Identities&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#infinite-unions-and-intersections&quot; id=&quot;markdown-toc-infinite-unions-and-intersections&quot;&gt;Infinite Unions and Intersections&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#disjoint-events&quot; id=&quot;markdown-toc-disjoint-events&quot;&gt;Disjoint Events&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#partitions&quot; id=&quot;markdown-toc-partitions&quot;&gt;Partitions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sample-space-and-events&quot;&gt;Sample Space and Events&lt;/h2&gt;

&lt;p&gt;In statistics, we often deal with experiments or processes that yield outcomes.
The &lt;strong&gt;sample space&lt;/strong&gt; is the set of all possible outcomes of an experiment or process.
An &lt;strong&gt;event&lt;/strong&gt; is a subset of the sample space, representing a specific outcome or a group of outcomes that we are interested in.
We can classify sample spaces into two types:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Countable Sample Space&lt;/strong&gt;: A sample space is countable if it can be put into a one-to-one correspondence with the set of natural numbers.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Uncountable Sample Space&lt;/strong&gt;: A sample space is uncountable if it cannot be put into a one-to-one correspondence with the set of natural numbers, such as the set of real numbers.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For example, the sample space of rolling a die $S = \set{1, 2, 3, 4, 5, 6 }$ is countable, while the sample space of measuring the height of a person is uncountable (it can take any real value within a certain range).&lt;/p&gt;

&lt;h2 id=&quot;set-relationships-and-operations&quot;&gt;Set Relationships and Operations&lt;/h2&gt;

&lt;p&gt;We first need to define the following two relationships between events (or sets; implying that we are using set theory):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Containment&lt;/strong&gt;: $A\subset B \iff (\forall x\in A \implies x\in B) $&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Equality&lt;/strong&gt;: $A = B \iff (A\subset B \land B\subset A) $&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Also, we have the following elementary set operations:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Union&lt;/strong&gt;: $A \cup B = \set{x \mid x \in A \lor x \in B}$&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Intersection&lt;/strong&gt;: $A \cap B = \set{x \mid x \in A \land x \in B}$&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Complementation&lt;/strong&gt;: $A^\complement = \set{x \mid x \notin A}$&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;elementary-identities&quot;&gt;Elementary Identities&lt;/h3&gt;

&lt;p&gt;For any events, $A$, $B$, and $C$, defined on a sample space $S$, the following identities hold:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Commutativity&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;$A \cup B = B \cup A$&lt;/li&gt;
      &lt;li&gt;$A \cap B = B \cap A$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Associativity&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;$(A \cup B) \cup C = A \cup (B \cup C)$&lt;/li&gt;
      &lt;li&gt;$(A \cap B) \cap C = A \cap (B \cap C)$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Distributivity&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;$A \cup (B \cap C) = (A \cup B) \cap (A \cup C)$&lt;/li&gt;
      &lt;li&gt;$A \cap (B \cup C) = (A \cap B) \cup (A \cap C)$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;De Morgan’s Laws&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;$(A \cup B)^\complement = A^\complement \cap B^\complement$&lt;/li&gt;
      &lt;li&gt;$(A \cap B)^\complement = A^\complement \cup B^\complement$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Proofs of these identities are left as a workout for set theory readers.&lt;/p&gt;

&lt;h3 id=&quot;infinite-unions-and-intersections&quot;&gt;Infinite Unions and Intersections&lt;/h3&gt;

&lt;p&gt;Since the associativity of union and intersection holds, we can extend these operations to infinite collections of sets.&lt;/p&gt;

&lt;p&gt;For any collection of sets $\set{A_i}_{i \in I}$ indexed by some index set $I$, we define:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Infinite Union&lt;/strong&gt;:
\[ \bigcup_{i \in I} A_i = \Set{x \mid \exists i \in I, x \in A_i} \]&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Infinite Intersection&lt;/strong&gt;:
\[ \bigcap_{i \in I} A_i = \Set{x \mid \forall i \in I, x \in A_i} \]&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here the index set $I$ can be any set, including infinite sets, and the definitions extend the finite cases to infinite collections of sets.&lt;/p&gt;

&lt;h2 id=&quot;disjoint-events&quot;&gt;Disjoint Events&lt;/h2&gt;

&lt;p&gt;Two events (or sets) $A$ and $B$ are said to be &lt;strong&gt;disjoint&lt;/strong&gt; (or mutually exclusive) they have no elements in common, i.e., $A \cap B = \emptyset$.
The events $A_1, A_2, \ldots, A_n$ are said to be &lt;strong&gt;pairwise disjoint&lt;/strong&gt; if for any $i \neq j$, $A_i \cap A_j = \emptyset$.
Disjoint sets are sets that do not overlap, meaning they do not share any elements.&lt;/p&gt;

&lt;h2 id=&quot;partitions&quot;&gt;Partitions&lt;/h2&gt;

&lt;p&gt;If $\set{A_i}_{i \in I}$ are pairwise disjoint events such that satisfies,
$\bigcup_{i\in I} A_i = S$, then we say that $ \set{A_i}_{i \in I} $ is a &lt;strong&gt;partition&lt;/strong&gt; of the sample space $S$.&lt;/p&gt;</content><author><name>Jiho Jun</name><email>pianoforte0203@gmail.com</email></author><category term="mathematics" /><category term="statistics" /><summary type="html"></summary></entry></feed>